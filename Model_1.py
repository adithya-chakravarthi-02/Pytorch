# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZdeJa7iPzpJaCQCW1iekbpMjOIZMn3WM
"""

drive.mount('/content/drive')

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import numpy as np
import nibabel as nib
import os
from google.colab import drive
import h5py

class UNet(nn.Module):
    def __init__(self):
        super(UNet, self).__init__()
        self.conv1 = nn.Conv2d(4, 64, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.upconv = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.final = nn.Conv2d(64, 1, kernel_size=1)

    def forward(self, x):
        x1 = F.relu(self.conv1(x))
        x2 = self.pool(F.relu(self.conv2(x1)))
        x3 = self.upconv(x2)
        return torch.sigmoid(self.final(x3))

class BraTSDataset(Dataset):
    def __init__(self,image_dir,mask_dir):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.images = os.listdir(self.image_dir)
    def __len__(self):
        return len(self.images)
    def __getitem__(self,idx):
        img_path = os.path.join(self.image_dir,self.images[idx])
        mask_path = os.path.join(self.mask_dir,self.images[idx])
        image_nifti = nib.load(img_path).get_fdata()
        mask_nifti = nib.load(mask_path).get_fdata()

        image = np.array(image_nifti,dtype=np.float32)
        mask = np.array(mask_nifti,dtype=np.float32)

        image = (image-np.min(image))/(np.max(image) - np.min(image))
        mask = (mask>0).astype(np.float32)

        image = torch.tensor(image, dtype=torch.float32)
        mask = torch.tensor(mask, dtype=torch.float32)

        return image,mask

base_path = '/content/drive/My Drive/3/BraTS2020_training_data'
train_image_path = os.path.join(base_path,"content")

train_dataset = data(train_image_path,train_mask_path)
train_loader = DataLoader(train_dataset,batch_size=4,shuffle =True)

Model = UNet()
criterion = nn.BCELoss()
optimizer = torch.optim.Adam(Model.parameters(), lr=0.001)

epochs = 20
for epoch in range(epochs):
  for images, mask in train_loader:
    optimizer.zero_grad()
    output = Model(images)
    loss = criterion(output,mask)
    loss.backward()
    optimizer.step()
  print(f"epochs {epoch+1}/{epochs}, Loss: {loss.item():.4f}")

